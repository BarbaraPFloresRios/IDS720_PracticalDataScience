{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values Exercises\n",
    "\n",
    "<span style=\"color: #008080\">*Jiechen Li*</span>\n",
    "\n",
    "<span style=\"color: #008080\">*Bárbara Flores*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradescope Autograding\n",
    "\n",
    "Please follow [all standard guidance](https://www.practicaldatascience.org/html/autograder_guidelines.html) for submitting this assignment to the Gradescope autograder, including storing your solutions in a dictionary called `results` and ensuring your notebook runs from the start to completion without any errors.\n",
    "\n",
    "For this assignment, please name your file `exercise_missing.ipynb` before uploading.\n",
    "\n",
    "You can check that you have answers for all questions in your `results` dictionary with this code:\n",
    "\n",
    "\n",
    "```python\n",
    "assert set(results.keys()) == {\n",
    "    \"ex2_avg_income\",\n",
    "    \"ex3_share_making_9999999\",\n",
    "    \"ex3_share_making_zero\",\n",
    "    \"ex5_avg_income\",\n",
    "    \"ex8_avg_income_black\",\n",
    "    \"ex8_avg_income_white\",\n",
    "    \"ex8_racial_difference\",\n",
    "    \"ex9_avg_income_black\",\n",
    "    \"ex9_avg_income_white\",\n",
    "    \"ex10_wage_gap\",\n",
    "}\n",
    "```\n",
    "\n",
    "### Submission Limits\n",
    "\n",
    "Please remember that you are **only allowed three submissions to the autograder.** Your last submission (if you submit 3 or fewer times), or your third submission (if you submit more than 3 times) will determine your grade Submissions that error out will **not** count against this total.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Today, we will be using the ACS data we used during out first `pandas` exercise to examine the US income distribution, and how it varies by race. Note that because the US income distribution has a very small number of people with *extremely* high incomes, and the ACS is just a sample of Americans, the far right tail of the distribution will not be very well estimated. However, this data should suffice for helping to understand wealth inequality in the United States. \n",
    "\n",
    "To begin, load the ACS Data we used in our first pandas exercise. That [data can be found here](https://github.com/nickeubank/MIDS_Data/tree/master/US_AmericanCommunitySurvey). We'll be working with `US_ACS_2017_10pct_sample.dta`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>datanum</th>\n",
       "      <th>serial</th>\n",
       "      <th>cbserial</th>\n",
       "      <th>numprec</th>\n",
       "      <th>subsamp</th>\n",
       "      <th>hhwt</th>\n",
       "      <th>hhtype</th>\n",
       "      <th>cluster</th>\n",
       "      <th>adjust</th>\n",
       "      <th>...</th>\n",
       "      <th>migcounty1</th>\n",
       "      <th>migmet131</th>\n",
       "      <th>vetdisab</th>\n",
       "      <th>diffrem</th>\n",
       "      <th>diffphys</th>\n",
       "      <th>diffmob</th>\n",
       "      <th>diffcare</th>\n",
       "      <th>diffsens</th>\n",
       "      <th>diffeye</th>\n",
       "      <th>diffhear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>177686</td>\n",
       "      <td>2.017001e+12</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>55</td>\n",
       "      <td>female householder, no husband present</td>\n",
       "      <td>2.017002e+12</td>\n",
       "      <td>1.011189</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>not in identifiable area</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>no vision or hearing difficulty</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1200045</td>\n",
       "      <td>2.017001e+12</td>\n",
       "      <td>6</td>\n",
       "      <td>79</td>\n",
       "      <td>25</td>\n",
       "      <td>male householder, no wife present</td>\n",
       "      <td>2.017012e+12</td>\n",
       "      <td>1.011189</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>not in identifiable area</td>\n",
       "      <td>n/a</td>\n",
       "      <td>no cognitive difficulty</td>\n",
       "      <td>no ambulatory difficulty</td>\n",
       "      <td>no independent living difficulty</td>\n",
       "      <td>no</td>\n",
       "      <td>no vision or hearing difficulty</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>70831</td>\n",
       "      <td>2.017000e+12</td>\n",
       "      <td>1 person record</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>male householder, living alone</td>\n",
       "      <td>2.017001e+12</td>\n",
       "      <td>1.011189</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>not in identifiable area</td>\n",
       "      <td>n/a</td>\n",
       "      <td>has cognitive difficulty</td>\n",
       "      <td>no ambulatory difficulty</td>\n",
       "      <td>no independent living difficulty</td>\n",
       "      <td>no</td>\n",
       "      <td>no vision or hearing difficulty</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>557128</td>\n",
       "      <td>2.017001e+12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "      <td>married-couple family household</td>\n",
       "      <td>2.017006e+12</td>\n",
       "      <td>1.011189</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>not in identifiable area</td>\n",
       "      <td>n/a</td>\n",
       "      <td>no cognitive difficulty</td>\n",
       "      <td>no ambulatory difficulty</td>\n",
       "      <td>no independent living difficulty</td>\n",
       "      <td>no</td>\n",
       "      <td>no vision or hearing difficulty</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>614890</td>\n",
       "      <td>2.017001e+12</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>54</td>\n",
       "      <td>married-couple family household</td>\n",
       "      <td>2.017006e+12</td>\n",
       "      <td>1.011189</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>not in identifiable area</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>no vision or hearing difficulty</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  datanum   serial      cbserial          numprec subsamp  hhwt  \\\n",
       "0  2017        1   177686  2.017001e+12                9      64    55   \n",
       "1  2017        1  1200045  2.017001e+12                6      79    25   \n",
       "2  2017        1    70831  2.017000e+12  1 person record      36    57   \n",
       "3  2017        1   557128  2.017001e+12                2      10    98   \n",
       "4  2017        1   614890  2.017001e+12                4      96    54   \n",
       "\n",
       "                                   hhtype       cluster    adjust  ...  \\\n",
       "0  female householder, no husband present  2.017002e+12  1.011189  ...   \n",
       "1       male householder, no wife present  2.017012e+12  1.011189  ...   \n",
       "2          male householder, living alone  2.017001e+12  1.011189  ...   \n",
       "3         married-couple family household  2.017006e+12  1.011189  ...   \n",
       "4         married-couple family household  2.017006e+12  1.011189  ...   \n",
       "\n",
       "   migcounty1                 migmet131 vetdisab                   diffrem  \\\n",
       "0           0  not in identifiable area      n/a                       n/a   \n",
       "1           0  not in identifiable area      n/a   no cognitive difficulty   \n",
       "2           0  not in identifiable area      n/a  has cognitive difficulty   \n",
       "3           0  not in identifiable area      n/a   no cognitive difficulty   \n",
       "4           0  not in identifiable area      n/a                       n/a   \n",
       "\n",
       "                   diffphys                           diffmob diffcare  \\\n",
       "0                       n/a                               n/a      n/a   \n",
       "1  no ambulatory difficulty  no independent living difficulty       no   \n",
       "2  no ambulatory difficulty  no independent living difficulty       no   \n",
       "3  no ambulatory difficulty  no independent living difficulty       no   \n",
       "4                       n/a                               n/a      n/a   \n",
       "\n",
       "                          diffsens  diffeye  diffhear  \n",
       "0  no vision or hearing difficulty       no        no  \n",
       "1  no vision or hearing difficulty       no        no  \n",
       "2  no vision or hearing difficulty       no        no  \n",
       "3  no vision or hearing difficulty       no        no  \n",
       "4  no vision or hearing difficulty       no        no  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_stata(\n",
    "    \"https://github.com/nickeubank/MIDS_Data/raw/master/US_AmericanCommunitySurvey/US_ACS_2017_10pct_sample.dta\"\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Let's begin by calculating the mean US incomes from this data (recall that income is stored in the `inctot` variable). Store the answer in `results` under the key `\"ex2_avg_income\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean US income in this sample is 1,723,646\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "ex2_avg_income = data[\"inctot\"].mean()\n",
    "results[\"ex2_avg_income\"] = ex2_avg_income\n",
    "\n",
    "\n",
    "print(f\"The mean US income in this sample is {round(ex2_avg_income):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Hmmm... That doesn't look right. The average American is definitely not earning that much a year! Let's look at the values of `inctot` using `value_counts()`. Do you see a problem?\n",
    "\n",
    "Now use `value_counts()` with the argument `normalize=True` to see proportions of the sample that report each value instead of the count of people in each category. What percentage of our sample has an income of 9,999,999? Store that proportion (between 0 and 1) as `\"ex3_share_making_9999999\"`. What percentage has an income of 0? Store that proportion as `\"ex3_share_making_zero\"`.\n",
    "\n",
    "(Recall `.value_counts()` returns a Series, so you can pull values out with our usual pandas tools.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's see how the proportions of the income sample behave.\n",
      "\n",
      "inctot\n",
      "9999999    0.168967\n",
      "0          0.105575\n",
      "30000      0.014978\n",
      "50000      0.013837\n",
      "40000      0.013834\n",
      "             ...   \n",
      "70520      0.000003\n",
      "76680      0.000003\n",
      "57760      0.000003\n",
      "200310     0.000003\n",
      "505400     0.000003\n",
      "Name: proportion, Length: 8471, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's see how the proportions of the income sample behave.\\n\")\n",
    "sumarize = data[\"inctot\"].value_counts(normalize=True)\n",
    "print(sumarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of the sample with an income of 9,999,999 is 0.169.\n",
      "The proportion of the sample with an income of 0 is 0.106.\n"
     ]
    }
   ],
   "source": [
    "ex3_share_making_9999999 = sumarize[9999999]\n",
    "ex3_share_making_zero = sumarize[0]\n",
    "\n",
    "results[\"ex3_share_making_9999999\"] = ex3_share_making_9999999\n",
    "results[\"ex3_share_making_zero\"] = ex3_share_making_zero\n",
    "\n",
    "print(\n",
    "    f\"The proportion of the sample with an income of 9,999,999 is {round(ex3_share_making_9999999,3)}.\"\n",
    ")\n",
    "print(\n",
    "    f\"The proportion of the sample with an income of 0 is {round(ex3_share_making_zero, 3)}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "As we discussed before, the ACS uses a value of 9999999 to denote that income information is not available for someone. The problem with using this kind of \"sentinel value\" is that pandas doesn't understand that this is supposed to denote missing data, and so when it averages the variable, it doesn't know to ignore 9999999. \n",
    "\n",
    "To help out `pandas`, use the `replace` command to replace all values of 9999999 with `np.nan`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing the values of 999 with NaN, we observe the following resulting proportions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inctot\n",
       "0.0         0.127041\n",
       "30000.0     0.018023\n",
       "50000.0     0.016650\n",
       "40000.0     0.016646\n",
       "20000.0     0.015341\n",
       "              ...   \n",
       "246600.0    0.000004\n",
       "90810.0     0.000004\n",
       "341380.0    0.000004\n",
       "15790.0     0.000004\n",
       "505400.0    0.000004\n",
       "Name: proportion, Length: 8470, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\n",
    "    \"Replacing the values of 999 with NaN, we observe the following resulting proportions:\"\n",
    ")\n",
    "\n",
    "data[\"inctot\"] = data[\"inctot\"].replace(9999999, np.nan)\n",
    "data[\"inctot\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Now that we've properly labeled our missing data as `np.nan`, let's calculate the average US income once more. Store the answer in `results` under the key `\"ex5_avg_income\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean US income in this sample, without considering values of 9999999, is 40,890\n"
     ]
    }
   ],
   "source": [
    "ex5_avg_income = data[\"inctot\"].mean()\n",
    "results[\"ex5_avg_income\"] = ex5_avg_income\n",
    "\n",
    "print(\n",
    "    f\"The mean US income in this sample, without considering values of 9999999, is {round(ex5_avg_income):,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "OK, now we've been able to get a reasonable average income number. As we can see, a major advantage of using `np.nan` is that `pandas` knows that `np.nan` observations should just be ignored when we are calculating means. \n",
    "\n",
    "But it's not enough to just get rid of the people who had `inctot` values of 9999999. We also need to know why those values were missing. Suppose, for example, that the value of 9999999 was used for anyone who made more than 100,000 dollars: if we just dropped those people, then our estimate of average income wouldn't mean much, would it?\n",
    "\n",
    "So let's make sure we understand *why* data is missing for some people. If you recall from our last exercise, it seemed to be the case that most of the people who had incomes of 9999999 were children. Let's make sure that's true by looking at the distribution of the variable `age` for people for whom `inctot` is missing (i.e. subset the data to people with `inctot` missing, then look at the values of `age` with `value_counts()`).\n",
    "\n",
    "Then do the opposite: look at the distribution of the `age` variable for people who whom `inctot` is *not* missing. \n",
    "\n",
    "Can you determine when 9999999 was being used? Is it ok we're excluding those people from our analysis?\n",
    "\n",
    "Note: In this data, Python doesn't understand `age` is a number; it thinks it is a string because the original data has categories like \"90 (90+ in 1980 and 1990)\" and \"less than 1 year old\". So you can't just use `min()` or `max()`. We'll discuss converting string variables into numbers in a future class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less than 1 year old 3150\n",
      "1 3340\n",
      "2 3405\n",
      "3 3220\n",
      "4 3318\n",
      "5 3512\n",
      "6 3524\n",
      "7 3527\n",
      "8 3648\n",
      "9 3977\n",
      "10 3997\n",
      "11 3791\n",
      "12 3845\n",
      "13 3800\n",
      "14 3847\n",
      "15 0\n",
      "16 0\n",
      "17 0\n",
      "18 0\n",
      "19 0\n",
      "20 0\n",
      "21 0\n",
      "22 0\n",
      "23 0\n",
      "24 0\n",
      "25 0\n",
      "26 0\n",
      "27 0\n",
      "28 0\n",
      "29 0\n",
      "30 0\n",
      "31 0\n",
      "32 0\n",
      "33 0\n",
      "34 0\n",
      "35 0\n",
      "36 0\n",
      "37 0\n",
      "38 0\n",
      "39 0\n",
      "40 0\n",
      "41 0\n",
      "42 0\n",
      "43 0\n",
      "44 0\n",
      "45 0\n",
      "46 0\n",
      "47 0\n",
      "48 0\n",
      "49 0\n",
      "50 0\n",
      "51 0\n",
      "52 0\n",
      "53 0\n",
      "54 0\n",
      "55 0\n",
      "56 0\n",
      "57 0\n",
      "58 0\n",
      "59 0\n",
      "60 0\n",
      "61 0\n",
      "62 0\n",
      "63 0\n",
      "64 0\n",
      "65 0\n",
      "66 0\n",
      "67 0\n",
      "68 0\n",
      "69 0\n",
      "70 0\n",
      "71 0\n",
      "72 0\n",
      "73 0\n",
      "74 0\n",
      "75 0\n",
      "76 0\n",
      "77 0\n",
      "78 0\n",
      "79 0\n",
      "80 0\n",
      "81 0\n",
      "82 0\n",
      "83 0\n",
      "84 0\n",
      "85 0\n",
      "86 0\n",
      "87 0\n",
      "88 0\n",
      "89 0\n",
      "90 (90+ in 1980 and 1990) 0\n",
      "91 0\n",
      "92 0\n",
      "93 0\n",
      "94 0\n",
      "95 0\n",
      "96 0\n"
     ]
    }
   ],
   "source": [
    "age_missing_inctot = data[pd.isna(data[\"inctot\"])][\"age\"].value_counts().sort_index()\n",
    "for age, count in age_missing_inctot.items():\n",
    "    print(age, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less than 1 year old 0\n",
      "1 0\n",
      "2 0\n",
      "3 0\n",
      "4 0\n",
      "5 0\n",
      "6 0\n",
      "7 0\n",
      "8 0\n",
      "9 0\n",
      "10 0\n",
      "11 0\n",
      "12 0\n",
      "13 0\n",
      "14 0\n",
      "15 3942\n",
      "16 4106\n",
      "17 4021\n",
      "18 4496\n",
      "19 4342\n",
      "20 3992\n",
      "21 3740\n",
      "22 3617\n",
      "23 3551\n",
      "24 3641\n",
      "25 3708\n",
      "26 3781\n",
      "27 3884\n",
      "28 3808\n",
      "29 3810\n",
      "30 3917\n",
      "31 3880\n",
      "32 3883\n",
      "33 3734\n",
      "34 3942\n",
      "35 3867\n",
      "36 3834\n",
      "37 3870\n",
      "38 3718\n",
      "39 3783\n",
      "40 3884\n",
      "41 3487\n",
      "42 3603\n",
      "43 3573\n",
      "44 3656\n",
      "45 3939\n",
      "46 4064\n",
      "47 4256\n",
      "48 3956\n",
      "49 3940\n",
      "50 4272\n",
      "51 4021\n",
      "52 4418\n",
      "53 4600\n",
      "54 4821\n",
      "55 4693\n",
      "56 4776\n",
      "57 4720\n",
      "58 4734\n",
      "59 4776\n",
      "60 4950\n",
      "61 4644\n",
      "62 4614\n",
      "63 4488\n",
      "64 4287\n",
      "65 4362\n",
      "66 4106\n",
      "67 4055\n",
      "68 3951\n",
      "69 3877\n",
      "70 3953\n",
      "71 2917\n",
      "72 2901\n",
      "73 2781\n",
      "74 2819\n",
      "75 2532\n",
      "76 2170\n",
      "77 2089\n",
      "78 1985\n",
      "79 1758\n",
      "80 1721\n",
      "81 1524\n",
      "82 1464\n",
      "83 1335\n",
      "84 1157\n",
      "85 1117\n",
      "86 1041\n",
      "87 908\n",
      "88 859\n",
      "89 628\n",
      "90 (90+ in 1980 and 1990) 480\n",
      "91 227\n",
      "92 355\n",
      "93 476\n",
      "94 1035\n",
      "95 471\n",
      "96 10\n"
     ]
    }
   ],
   "source": [
    "age_not_missing_inctot = (\n",
    "    data[~pd.isna(data[\"inctot\"])][\"age\"].value_counts().sort_index()\n",
    ")\n",
    "\n",
    "\n",
    "for age, count in age_not_missing_inctot.items():\n",
    "    print(age, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200859                           white\n",
       "51073                            white\n",
       "291890                 other race, nec\n",
       "202123                           white\n",
       "156555                 other race, nec\n",
       "198813    black/african american/negro\n",
       "103407                           white\n",
       "16531                            white\n",
       "161583                           white\n",
       "141212                         chinese\n",
       "58911                            white\n",
       "267444    black/african american/negro\n",
       "181725                           white\n",
       "211537                           white\n",
       "269276                           white\n",
       "263496                           white\n",
       "309396                           white\n",
       "265902                           white\n",
       "66210                            white\n",
       "28877                            white\n",
       "27449                            white\n",
       "246559                           white\n",
       "151910                           white\n",
       "282445                           white\n",
       "15813                  two major races\n",
       "230946                           white\n",
       "88323                            white\n",
       "155634                           white\n",
       "54456                            white\n",
       "186695                           white\n",
       "Name: race, dtype: category\n",
       "Categories (9, object): ['white' < 'black/african american/negro' < 'american indian or alaska native' < 'chinese' ... 'other asian or pacific islander' < 'other race, nec' < 'two major races' < 'three or more major races']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"race\"].sample(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><span style=\"color: #008080\">*After analyzing the age distribution of the data where income is not missing versus the dataset where the value is missing, we can observe that for children under 14 years old, this value is missing, while for individuals aged 15 or older, this data is complete. This aligns with our hypothesis.*</span>\n",
    ">\n",
    "><span style=\"color: #008080\">*Given this situation, it is acceptable not to include the observations with 9999999 income, considering that we are analyzing data on the population of individuals who can legally work.*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "Great, so now we know why those people had missing data, and we're ok with excluding them. \n",
    "\n",
    "But as we previously noted, there are also a lot of observations of zero income in our data, and it's not clear that we want everyone with a zero-income *should* be included in this average, since those may be people who are retired, or in school. \n",
    "\n",
    "Let's limit our attention to people who are currently working by subsetting to only employed respondents. We can do this using `empstat`. Remember you can use `value_counts()` to see what values of `empstat` are in the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, let's look at how our variable 'empstat' is distributed.\n",
      "\n",
      "empstat\n",
      "employed              148758\n",
      "not in labor force    104676\n",
      "n/a                    57843\n",
      "unemployed              7727\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"First, let's look at how our variable 'empstat' is distributed.\\n\")\n",
    "print(data[\"empstat\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><span style=\"color: #008080\">*We can observe that a substantial portion of the database does not fall within the workforce, either due to retirement or being in school. It is crucial to consider this situation for future analyses.*</span>\n",
    ">\n",
    "><span style=\"color: #008080\">*Given that we want to analyze how salaries behave, we will limit our analysis to only those individuals who are employed. Therefore, we will select a subset of our data.*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "employed_data = data[data[\"empstat\"] == \"employed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "Now let's estimate the racial income gap in the United States. What is the average salary for employed Black Americans, and what is the average salary for employed White Americans? In percentage terms, how much more does the average White American make than the average Black American?\n",
    "\n",
    "**Note:** these values are not quite accurate estimates. As we'll discuss in later lessons, to get completely accurate estimates from the ACS we have to take into account how people were selected to be interviewed. But you get pretty good estimates in most cases even without weights—your estimate of the racial wage gap without weights is within 5\\% of the corrected value. \n",
    "\n",
    "**Note:** This is actually an underestimate of the wage gap. The US Census treats Hispanic respondents as a sub-category of \"White.\" While all ethnic distinctions are socially constructed, and so on some level these distinctions are all deeply problematic, this coding is inconsistent with what most Americans think of when they hear the term \"White,\" a term *most* Americans think of as a category that is mutually exclusive of being Hispanic or Latino (categories which are also usually conflated in American popular discussion). With that in mind, most researchers working with US Census data split \"White\" into \"White, Hispanic\" and \"White, Non-Hispanic\" using `race` *and* `hispan`. But for the moment, just identify \"White\" respondents using the value in `race`.\n",
    "\n",
    "Store your results in `results` under the keys `\"ex8_avg_income_black\"`, `\"ex8_avg_income_white\"`, and the percentage difference as `ex8_racial_difference`. Please note the wording above when calculating the percentage difference to ensure you get the reference category correct, and interpret your result as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's see how the variable 'race' is distributed in our dataset:\n",
      "\n",
      "race\n",
      "white                               116017\n",
      "black/african american/negro         13175\n",
      "other asian or pacific islander       6424\n",
      "other race, nec                       5755\n",
      "two major races                       3135\n",
      "chinese                               2149\n",
      "american indian or alaska native      1290\n",
      "three or more major races              426\n",
      "japanese                               387\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's see how the variable 'race' is distributed in our dataset:\\n\")\n",
    "print(employed_data[\"race\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average income for employed individuals who identify as Black in this sample is 41,748.\n",
      "The average income for employed individuals who identify as White in this sample is 60,473.\n",
      "\n",
      "In percentage terms, in this sample, the average income for employed White Americans\n",
      "is approximately  44.9% higher than the average salary for Black Americans.\n"
     ]
    }
   ],
   "source": [
    "# calculating results\n",
    "ex8_avg_income_black = employed_data[\n",
    "    employed_data[\"race\"] == \"black/african american/negro\"\n",
    "][\"inctot\"].mean()\n",
    "\n",
    "ex8_avg_income_white = employed_data[employed_data[\"race\"] == \"white\"][\"inctot\"].mean()\n",
    "\n",
    "ex8_racial_difference = (\n",
    "    (ex8_avg_income_white - ex8_avg_income_black) / ex8_avg_income_black * 100\n",
    ")\n",
    "\n",
    "# storing results\n",
    "results[\"ex8_avg_income_black\"] = ex8_avg_income_black\n",
    "results[\"ex8_avg_income_white\"] = ex8_avg_income_white\n",
    "results[\"ex8_racial_difference\"] = ex8_racial_difference\n",
    "\n",
    "# printing results\n",
    "print(\n",
    "    f\"The average income for employed individuals who identify as Black in this sample is {round(ex8_avg_income_black):,}.\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The average income for employed individuals who identify as White in this sample is {round(ex8_avg_income_white):,}.\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\nIn percentage terms, in this sample, the average income for employed White Americans\\nis approximately  {round(ex8_racial_difference,1):,}% higher than the average salary for Black Americans.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "\n",
    "As noted above, these estimates are not actually *quite* correct because we aren't using survey weights. To calculate a weighted average that takes into account survey weights, you need to use the following formula:\n",
    "\n",
    "$$weighted\\_mean\\_of\\_x = \\frac{\\sum_i x_i * weight_i}{\\sum_i weight_i}$$\n",
    "\n",
    "(As you can see, when $weight_i$ is constant for all observations, this just simplifies to our normal formula for mean values. It is only when weights vary across individuals that weights must be explicitly addressed).\n",
    "\n",
    "In this data, weights are stored in the variable `perwt`, which is the number of people for which each observation is a stand-in (the inverse of that observations sampling probability). \n",
    "\n",
    "Using the formula, re-calculate the *weighted* average income for both populations and store them as `ex9_avg_income_white` and `ex9_avg_income_black`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weighted average income for employed individuals who identify as Black in this sample is 40,431.\n",
      "The weighted average income for employed individuals who identify as White in this sample is 58,361.\n"
     ]
    }
   ],
   "source": [
    "# calculating results\n",
    "blk_weighted_sum = (\n",
    "    employed_data[employed_data[\"race\"] == \"black/african american/negro\"][\"inctot\"]\n",
    "    * employed_data[employed_data[\"race\"] == \"black/african american/negro\"][\"perwt\"]\n",
    ").sum()\n",
    "blk_total_weight = employed_data[\n",
    "    employed_data[\"race\"] == \"black/african american/negro\"\n",
    "][\"perwt\"].sum()\n",
    "\n",
    "ex9_avg_income_black = blk_weighted_sum / blk_total_weight\n",
    "\n",
    "white_weighted_sum = (\n",
    "    employed_data[employed_data[\"race\"] == \"white\"][\"inctot\"]\n",
    "    * employed_data[employed_data[\"race\"] == \"white\"][\"perwt\"]\n",
    ").sum()\n",
    "white_total_weight = employed_data[employed_data[\"race\"] == \"white\"][\"perwt\"].sum()\n",
    "ex9_avg_income_white = white_weighted_sum / white_total_weight\n",
    "\n",
    "# storing results\n",
    "results[\"ex9_avg_income_black\"] = ex9_avg_income_black\n",
    "results[\"ex9_avg_income_white\"] = ex9_avg_income_white\n",
    "\n",
    "# printin results\n",
    "print(\n",
    "    f\"The weighted average income for employed individuals who identify as Black in this sample is {round(ex9_avg_income_black):,}.\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The weighted average income for employed individuals who identify as White in this sample is {round(ex9_avg_income_white):,}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10\n",
    "\n",
    "Now calculate the weighted average income gap between *non-Hispanic* White Americans and Black Americans. What percentage more do employed White non-Hispanic Americans earn than employed Black Americans? Store as `\"ex10_wage_gap\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In percentage terms, in this sample, the weighted average income for employed White Non hispanic Americans\n",
      "is approximately  52.5% higher than the average salary for Black Americans.\n"
     ]
    }
   ],
   "source": [
    "# calculating results\n",
    "white_non_hispanic_employed_data = employed_data[\n",
    "    (employed_data[\"race\"] == \"white\") & (employed_data[\"hispan\"] == \"not hispanic\")\n",
    "]\n",
    "\n",
    "white_non_hispanic_avg_income_white = (\n",
    "    (\n",
    "        white_non_hispanic_employed_data[\"inctot\"]\n",
    "        * white_non_hispanic_employed_data[\"perwt\"]\n",
    "    ).sum()\n",
    ") / white_non_hispanic_employed_data[\"perwt\"].sum()\n",
    "\n",
    "\n",
    "ex10_wage_gap = (\n",
    "    (white_non_hispanic_avg_income_white - ex9_avg_income_black)\n",
    "    / ex9_avg_income_black\n",
    "    * 100\n",
    ")\n",
    "\n",
    "# storing results\n",
    "results[\"ex10_wage_gap\"] = ex10_wage_gap\n",
    "\n",
    "# printing results\n",
    "print(\n",
    "    f\"\\nIn percentage terms, in this sample, the weighted average income for employed White Non hispanic Americans\\nis approximately  {round(ex10_wage_gap,1):,}% higher than the average salary for Black Americans.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11\n",
    "\n",
    "Is that greater or less than the difference you found in Exercise 8? Why do you think that's the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><span style=\"color: #008080\">*The difference is greater than what was found in Exercise 8. The observed racial income gap is larger when considering only White Americans (52.5%) compared to when Hispanic respondents are included within the White category (44.9%). This suggests that the inclusion of Hispanics within the White category in the initial estimate generates a lower apparent racial income gap, leading to an underestimation of the true wage gap.*</span>\n",
    ">\n",
    "><span style=\"color: #008080\">*TIt is important to take these variables into consideration, especially when analyzing data for public policy purposes.*</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex2_avg_income': 1723646.2703978634,\n",
       " 'ex3_share_making_9999999': 0.1689665333350052,\n",
       " 'ex3_share_making_zero': 0.10557547867738336,\n",
       " 'ex5_avg_income': 40890.177564946454,\n",
       " 'ex8_avg_income_black': 41747.949905123336,\n",
       " 'ex8_avg_income_white': 60473.15372747098,\n",
       " 'ex8_racial_difference': 44.85299006275197,\n",
       " 'ex9_avg_income_black': 40430.953355310274,\n",
       " 'ex9_avg_income_white': 58361.48196061399,\n",
       " 'ex10_wage_gap': 52.52989147705372}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(results.keys()) == {\n",
    "    \"ex2_avg_income\",\n",
    "    \"ex3_share_making_9999999\",\n",
    "    \"ex3_share_making_zero\",\n",
    "    \"ex5_avg_income\",\n",
    "    \"ex8_avg_income_black\",\n",
    "    \"ex8_avg_income_white\",\n",
    "    \"ex8_racial_difference\",\n",
    "    \"ex9_avg_income_black\",\n",
    "    \"ex9_avg_income_white\",\n",
    "    \"ex10_wage_gap\",\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "718fed28bf9f8c7851519acf2fb923cd655120b36de3b67253eeb0428bd33d2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
